# practiceProjects-Gen-AI-Apps
Practice/Learning Projects from the Building Generative AI-Powered Applications with Python Course in the IBM AI Developer Certification on Coursera. 

**Building Generative AI-Powered Applications with Python - Practice Projects**

Welcome to my collection of practice projects completed as part of the Building Generative AI-Powered Applications with Python course on Coursera. These projects focus on building generative AI applications using Python, with a special emphasis on using cutting-edge models and frameworks.

**About This Repository**

This repository contains a series of Python-based practice projects that I completed as part of my coursework in Building Generative AI-Powered Applications with Python on Coursera. The projects cover key concepts in generative AI, such as building models that can generate text, images, and other data types.

The projects followed a structured curriculum and were based on step-by-step tutorials, where I learned how to implement various generative models.

**Course Link:**

https://www.coursera.org/learn/building-gen-ai-powered-applications

<br>
<br>

**Practice Project 1: Give Meaningful Names to Your Photos with AI**

**Description:**

In this project, I built an image captioning tool using the BLIP model (Bootstrapping Language-Image Pretraining) from Hugging Face’s Transformers library. The model generates captions for images by understanding both the visual content and contextual relationships within the image. I used Gradio to create a simple, user-friendly web interface that allows users to upload images and receive automatic captions.

**Learning Outcomes:**

- Learn how the BLIP model combines vision and language to generate meaningful captions for images.

- Use Hugging Face’s Transformers library to easily integrate pre-trained models into an application.

- Implement a user interface with Gradio, making it simple for non-technical users to interact with the AI model.

**Key Features:**

- Upload an image to the app.

- Automatically generate a caption describing the image.

- Interactive interface powered by Gradio for easy deployment.

**Technologies Used**

Programming Language: Python

Libraries/Frameworks:

- Hugging Face Transformers: For accessing pre-trained BLIP model.

- Gradio: For creating an interactive web interface to interact with the model.

- PIL (Python Imaging Library): For handling image processing.

- Torch: For running the deep learning model.

- NumPy: For numerical operations and data handling.

- Matplotlib: For displaying images (optional, if required for visualization).

- Requests: For making HTTP requests to fetch webpage content and images.

- BeautifulSoup: For parsing HTML content and extracting image URLs.

**A Note on the Project**

This project uses BLIP, a transformer-based model that combines vision and language understanding, to generate captions for uploaded images. It is designed to show how generative AI models can be applied to real-world tasks like image captioning.
The application is built using Gradio, a powerful library that simplifies the process of creating interactive, user-friendly web interfaces for AI models. This project serves as a practical example of how AI can be deployed and made accessible to end-users.

<br>

**Practice Project 2:**

**Description:**


**Learning Outcomes:**


**Key Features:**

-

**Technologies Used**

Programming Language: Python

Libraries/Frameworks:

-

**A Note on the Project**


<br>
